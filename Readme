# ğŸ¤–âœ¨ AI - Complete AI Chat System  

A **full-stack AI-powered chat application** with:  
âš¡ Intelligent model selection  
ğŸ’¬ Conversation management  
ğŸ¤– Real-time responses using **local AI models via Ollama**  

---

## ğŸ“Œ Prerequisites  
- ğŸŸ¢ Node.js (v18 or higher)  
- ğŸ Python (v3.8 or higher)  
- ğŸ¤– Ollama (for local AI models)  
- ğŸ”¥ Firebase account (for authentication)  

---

## âš™ï¸ ğŸš€ Installation & Setup (Single Flow)

```bash
###############################################
# ğŸ STEP 1: Python Backend Setup
###############################################

# Create and activate virtual environment
python -m venv venv
source venv/bin/activate   # ğŸ Linux/Mac
venv\Scripts\activate      # ğŸªŸ Windows

# Install Python dependencies
pip install flask flask-cors python-dotenv requests

# â–¶ï¸ Start Ollama service (keep running in Terminal 1)
ollama serve


###############################################
# ğŸ¨ STEP 2: Frontend Setup
###############################################

# Install Node.js dependencies
npm install

# Create environment configuration file
echo "LOCAL_AI_HOST=localhost
LOCAL_AI_PORT=5000
NEXT_PUBLIC_FIREBASE_API_KEY=your_firebase_api_key
NEXT_PUBLIC_FIREBASE_AUTH_DOMAIN=your_project.firebaseapp.com
NEXT_PUBLIC_FIREBASE_PROJECT_ID=your_project_id
NEXT_PUBLIC_FIREBASE_STORAGE_BUCKET=your_project.appspot.com
NEXT_PUBLIC_FIREBASE_MESSAGING_SENDER_ID=your_sender_id
NEXT_PUBLIC_FIREBASE_APP_ID=your_app_id" > .env.local


###############################################
# ğŸš¦ STEP 3: Start the Application
###############################################

# ğŸ–¥ï¸ Terminal 1 - Ollama Service
ollama serve

# ğŸ Terminal 2 - Python Backend
source venv/bin/activate   # ğŸ Linux/Mac
venv\Scripts\activate      # ğŸªŸ Windows
python app.py

# ğŸŒ Terminal 3 - Frontend
npm run dev


###############################################
# ğŸŒ Access the Application
###############################################

# Open your browser and go to:
ğŸ‘‰ http://localhost:3000


###############################################
# ğŸ”¥ Firebase Configuration
###############################################

# 1ï¸âƒ£ Create a Firebase project:
ğŸŒ https://console.firebase.google.com  

# 2ï¸âƒ£ Enable Authentication providers:
ğŸ“§ Email | ğŸŸ¦ Google | ğŸ“± Phone  

# 3ï¸âƒ£ Copy your Firebase config values into:
ğŸ“„ .env.local


###############################################
# âœ¨ Features
###############################################

ğŸ¤– Multi-Model AI Support  
ğŸ’¬ Smart Conversation Management  
ğŸ¨ Customizable UI Themes  
ğŸ” User Authentication  
âš¡ Real-time Responses  
ğŸ“± Responsive Design  


###############################################
# ğŸ› ï¸ Support / Troubleshooting
###############################################

âœ… Ensure Ollama is running  
âœ… Verify Python virtual environment is activated  
âœ… Check environment variables are correctly set  
âœ… Confirm ports 3000, 5000, and 11434 are free  


###############################################
# ğŸš€ Deployment Guide
###############################################

ğŸŒ Option 1: Vercel (Frontend)
--------------------------------
- Push frontend â¡ï¸ GitHub  
- Connect GitHub repo to Vercel  
- Add ğŸ”‘ env variables from `.env.local` in Vercel dashboard  
- Deploy ğŸš€ and get hosted frontend URL  

âš™ï¸ Option 2: Render / Heroku (Backend)
---------------------------------------
- Push backend â¡ï¸ GitHub  
- Create service on Render/Heroku  
- Add ğŸ”‘ env variables  
- Ensure Ollama service is running on server  
- Deploy ğŸ› ï¸ backend API  

â˜ï¸ Option 3: Local + Cloud Hybrid
-----------------------------------
- Host frontend on **Vercel**  
- Run backend + Ollama **locally or on cloud VM**  
- Update frontend API URLs ğŸ”— to your backend server  






âš–ï¸ License

Â© 2025 Infrablitz. All rights reserved. ğŸŒ infrablitz.com
